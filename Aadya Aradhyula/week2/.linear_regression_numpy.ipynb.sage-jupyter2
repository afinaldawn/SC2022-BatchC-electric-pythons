{"backend_state":"init","connection_file":"/projects/0bcf82e6-7441-4432-a339-19b67c22cc5c/.local/share/jupyter/runtime/kernel-96a3d42d-b55e-47aa-bd4c-0fe71cac713d.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"colab":{"name":"linear_regression_numpy_tutorial.ipynb","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"41a672","input":"","metadata":{"id":"cvxyHdHha-sa"},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"780e98","input":"# import libraries \nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1627498066861,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"IecuRdF1a-sG"},"pos":1,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"faa420","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42) # Why 42 (It works well for computer science) - https://medium.com/@leticia.b/the-story-of-seed-42-874953452b94\n\n# randomly generate x which is a vector of 100 points \nx = np.random.rand(100, 1)\n\n# define exact linear function y = 1 + 2x + epsilon where epsilon (0.1*random numbers)\ny = 1 + 2 * x + .1 * np.random.randn(100, 1)","metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1627498568931,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"BYHvay0xa-sK"},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"4803b3","input":"# initialize your random seed to ensure reproducibility of your result\nnp.random.seed(42)\n\n# Initializes parameters \"a\" and \"b\" randomly - they don't need to be good yet\na = np.random.randn(1)\nb = np.random.randn(1)\n\n# print values of a and b \nprint(a, b)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1627498594869,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"MjeQPrOKa-sP","outputId":"fe881c09-932e-46f0-9f40-79b6b5c69617"},"output":{"0":{"name":"stdout","output_type":"stream","text":"[0.49671415] [-0.1382643]\n"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"7abfda","input":"# Initialization of hyper-parameters (in our case, only learning rate and number of epochs)\n\n# Sets learning rate (how much the AI conforms to each set of feedbacks)\nlr = 1e-1\n# Defines number of epochs (how many times training is repeated)\nn_epochs = 1000","metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1627498605594,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"xaIPfjB1a-sP"},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"af3982","input":"plt.figure(figsize=(10,5))\ny_vals = b + a * x_val\nplt.plot(x_val, y_vals, '--')\n\nplt.scatter(x_val,y_val, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Train')\nplt.grid('on')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1627499225902,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"V9wnGeT_eou8","outputId":"1dc573e8-ebd4-4861-94e0-ff1a6d4229d3"},"output":{"0":{"data":{"image/png":"dc43e6c5cd70ea4a132afbbacd5f42b590eef900","text/plain":"<Figure size 720x360 with 1 Axes>"},"exec_count":15,"metadata":{"needs_background":"light","tags":[]},"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"b5d363","input":"for epoch in range(n_epochs):\n    # Computes our model's predicted output\n    yhat = a + b * x_train\n    \n    # How wrong is our model? That's the error! \n    error = (y_train - yhat)\n    \n    # It is a regression, so it computes mean squared error (MSE)\n    loss = (error ** 2).mean()\n    \n    # Computes gradients for both \"a\" and \"b\" parameters\n    a_grad = -2 * error.mean()\n    b_grad = -2 * (x_train * error).mean()\n    \n    # Updates parameters using gradients and the learning rate\n    a = a - lr * a_grad\n    b = b - lr * b_grad\n    \nprint(a, b)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1627499222901,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"IEGhbnhoa-sQ","outputId":"6df14990-801c-4030-bd27-e2c19b95c577"},"output":{"0":{"name":"stdout","output_type":"stream","text":"[1.0242157] [1.95032842]\n"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"6efa4e","input":"from sklearn.linear_model import LinearRegression\nlinr = LinearRegression()\nlinr.fit(x_train, y_train)\nprint(linr.intercept_, linr.coef_[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":885,"status":"ok","timestamp":1627498630865,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"jkPf0bt4a-sV","outputId":"422ab4c2-fceb-490e-ca2d-b45f09b26cff"},"output":{"0":{"name":"stdout","output_type":"stream","text":"[1.0242157] [1.95032842]\n"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"59ef13","input":"from sklearn.linear_model import LinearRegression\nlinr = LinearRegression()\nlinr.fit(x_train, y_train)","metadata":{"id":"owTTVO4Ba-sY"},"output":{"0":{"data":{"text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>","text/plain":"LinearRegression()"},"exec_count":17,"output_type":"execute_result"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"f7a6cb","input":"linr.get_params()","metadata":{"id":"l5xP_R3ya-sZ"},"output":{"0":{"data":{"text/plain":"{'copy_X': True,\n 'fit_intercept': True,\n 'n_jobs': None,\n 'normalize': 'deprecated',\n 'positive': False}"},"exec_count":18,"output_type":"execute_result"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"740f45","input":"pred = linr.predict(x_val)\npred","metadata":{"id":"8vkl-uJMa-sZ"},"output":{"0":{"data":{"text/plain":"array([[1.14817536],\n       [2.03851914],\n       [2.87485414],\n       [1.65842998],\n       [2.11889057],\n       [1.75469194],\n       [2.91585845],\n       [2.19658739],\n       [1.59399371],\n       [1.55343543],\n       [2.52785491],\n       [1.94518989],\n       [2.19031702],\n       [1.40644665],\n       [2.41527728],\n       [1.07379135],\n       [2.64052602],\n       [1.61758799],\n       [1.86665035],\n       [1.11480926]])"},"exec_count":19,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"6e8beb","input":"linr.score(pred, y_val)","metadata":{"id":"mdxlUKLka-sZ"},"output":{"0":{"data":{"text/plain":"-26.58096856005112"},"exec_count":20,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"ea7e43","input":"y_val","metadata":{"id":"bUuZFIRxa-sZ"},"output":{"0":{"data":{"text/plain":"array([[1.19277206],\n       [1.89995094],\n       [2.89032648],\n       [1.7290751 ],\n       [2.04718078],\n       [1.75778494],\n       [2.97269482],\n       [2.12138066],\n       [1.58480064],\n       [1.51049191],\n       [2.45298292],\n       [1.98570794],\n       [2.04073361],\n       [1.43932497],\n       [2.61616887],\n       [1.07850733],\n       [2.73882674],\n       [1.53827918],\n       [1.82467922],\n       [1.13330591]])"},"exec_count":21,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"ac92a2","input":"plt.figure(figsize=(10,5))\n\n# plot the train set \nplt.subplot(1,2,1)\nplt.scatter(x_train,y_train, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Train')\nplt.grid('on')\n\n# plot the validation set \nplt.subplot(1,2,2)\nplt.scatter(x_val,x_val)  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\n\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1627498583872,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"W1JhyZ_Na-sM","outputId":"909f5fd9-c203-45cf-d41f-58b09bb727ef"},"output":{"0":{"data":{"image/png":"f075f4d1128da421683b3b7123675e91e79d107a","text/plain":"<Figure size 720x360 with 2 Axes>"},"exec_count":4,"metadata":{"needs_background":"light","tags":[]},"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"0b1e03","input":"# Shuffles the indices\nidx = np.arange(100)\nnp.random.shuffle(idx)\n\n# Uses first 80 random indices for train\ntrain_idx = idx[:80]\n\n# Uses the remaining indices for validation\nval_idx = idx[80:]\n\n# Generates train and validation sets\nx_train, y_train = x[train_idx], y[train_idx]\nx_val, y_val = x[val_idx], y[val_idx]\n","metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1627498579768,"user":{"displayName":"Fernanda Murillo","photoUrl":"","userId":"17562885266255337733"},"user_tz":600},"id":"_ntl2sX3a-sL"},"pos":5,"type":"cell"}
{"cell_type":"markdown","id":"28f0e7","input":"## linear regression using numpy ","metadata":{"id":"gi4pQP8Ia-sO"},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"4b9544","input":"## split data into train and validation sets (80/20)","metadata":{"id":"irEOBQoca-sL"},"pos":4,"type":"cell"}
{"cell_type":"markdown","id":"527477","input":"## The results!\n\nThey match up to 6 decimal places — we have a fully working implementation of linear regression using Numpy.","metadata":{"id":"yE4V3P9aa-sX"},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"60e26a","input":"### For each epoch, there are 5 training steps:\n* Compute model’s predictions \n* Compute the error (the difference between the actual value and predicted value) \n* Compute the loss ( mean square error = the average of (error)^2)\n* Compute the gradients for every parameter (require calculus)\n* Update the parameters a and b","metadata":{"id":"Tmk5nl_Va-sQ"},"pos":11,"type":"cell"}
{"cell_type":"markdown","id":"c88498","input":"## plot the train and validation sets","metadata":{"id":"DCCwyhkya-sM"},"pos":6,"type":"cell"}
{"cell_type":"markdown","id":"dc7495","input":"# Linear regression using NumPy","metadata":{"id":"K_X2fB9ta-rv"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"e05da7","input":"## check our results use Scikit-learn's linear regression\n\nJust to make sure we haven’t done any mistakes in our code, we can use Scikit-Learn’s Linear Regression to fit the model and compare the coefficients.\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html","metadata":{"id":"cbeaQMpna-sR"},"pos":14,"type":"cell"}
{"cell_type":"markdown","id":"fe38eb","input":"## Data Generation","metadata":{"id":"JlrQHpg8a-sI"},"pos":2,"type":"cell"}
{"id":0,"time":1659025270508,"type":"user"}
{"last_load":1659025263196,"type":"file"}